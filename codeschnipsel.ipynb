{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae06576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_wikidata_refined(identifiers, exchange_qid, mode=\"isin\"):\n",
    "    url = 'https://query.wikidata.org/sparql'\n",
    "    \n",
    "    if mode == \"isin\":\n",
    "        values_formatted = ' '.join([f'\"{i}\"' for i in identifiers])\n",
    "        lookup_logic = \"?company wdt:P946 ?reqId . BIND(?reqId AS ?isin)\"\n",
    "    else:\n",
    "        values_formatted = ' '.join([f'\"{t}\"' for t in identifiers])\n",
    "        lookup_logic = f\"?company p:P414 [ ps:P414 wd:{exchange_qid} ; pq:P249 ?reqId ] . OPTIONAL {{ ?company wdt:P946 ?isin . }}\"\n",
    "\n",
    "    query = f\"\"\"\n",
    "    SELECT ?reqId ?company ?companyLabel ?isin ?foundingYear\n",
    "      (GROUP_CONCAT(DISTINCT ?sub_info; separator=\"|\") AS ?subs_combined)\n",
    "      (GROUP_CONCAT(DISTINCT ?ind_info; separator=\"|\") AS ?inds_combined)\n",
    "      (GROUP_CONCAT(DISTINCT ?inv_info; separator=\"|\") AS ?invs_combined)\n",
    "      (GROUP_CONCAT(DISTINCT ?prod_info; separator=\"|\") AS ?prods_combined)\n",
    "      (GROUP_CONCAT(DISTINCT ?area_info; separator=\"|\") AS ?areas_combined)\n",
    "      (GROUP_CONCAT(DISTINCT ?loc_info; separator=\"|\") AS ?locs_combined)\n",
    "      (GROUP_CONCAT(DISTINCT ?inst_info; separator=\"|\") AS ?insts_combined)\n",
    "      (GROUP_CONCAT(DISTINCT ?part_info; separator=\"|\") AS ?parts_combined)\n",
    "      (GROUP_CONCAT(DISTINCT ?owner_info; separator=\"|\") AS ?owners_combined)\n",
    "    WHERE {{\n",
    "      VALUES ?reqId {{ {values_formatted} }}\n",
    "      {lookup_logic}\n",
    "      \n",
    "      OPTIONAL {{ ?company wdt:P571 ?fDate . BIND(YEAR(?fDate) AS ?foundingYear) }}\n",
    "      \n",
    "      # Struktur: QID und Label werden vor dem GROUP_CONCAT kombiniert, das ist effizienter\n",
    "      OPTIONAL {{ ?company wdt:P355 ?sub . ?sub rdfs:label ?subL . FILTER(LANG(?subL) = \"en\") BIND(CONCAT(REPLACE(STR(?sub), \".*Q\", \"Q\"), \":\", ?subL) AS ?sub_info) }}\n",
    "      OPTIONAL {{ ?company wdt:P452 ?ind . ?ind rdfs:label ?indL . FILTER(LANG(?indL) = \"en\") BIND(CONCAT(REPLACE(STR(?ind), \".*Q\", \"Q\"), \":\", ?indL) AS ?ind_info) }}\n",
    "      OPTIONAL {{ ?company wdt:P1830 ?inv . ?inv rdfs:label ?invL . FILTER(LANG(?invL) = \"en\") BIND(CONCAT(REPLACE(STR(?inv), \".*Q\", \"Q\"), \":\", ?invL) AS ?inv_info) }}\n",
    "      OPTIONAL {{ ?company wdt:P1056 ?prod . ?prod rdfs:label ?prodL . FILTER(LANG(?prodL) = \"en\") BIND(CONCAT(REPLACE(STR(?prod), \".*Q\", \"Q\"), \":\", ?prodL) AS ?prod_info) }}\n",
    "      OPTIONAL {{ ?company wdt:P2541 ?area . ?area rdfs:label ?areaL . FILTER(LANG(?areaL) = \"en\") BIND(CONCAT(REPLACE(STR(?area), \".*Q\", \"Q\"), \":\", ?areaL) AS ?area_info) }}\n",
    "      OPTIONAL {{ ?company wdt:P276 ?loc . ?loc rdfs:label ?locL . FILTER(LANG(?locL) = \"en\") BIND(CONCAT(REPLACE(STR(?loc), \".*Q\", \"Q\"), \":\", ?locL) AS ?loc_info) }}\n",
    "      OPTIONAL {{ ?company wdt:P31 ?inst . ?inst rdfs:label ?instL . FILTER(LANG(?instL) = \"en\") BIND(CONCAT(REPLACE(STR(?inst), \".*Q\", \"Q\"), \":\", ?instL) AS ?inst_info) }}\n",
    "      OPTIONAL {{ ?company wdt:P361 ?part . ?part rdfs:label ?partL . FILTER(LANG(?partL) = \"en\") BIND(CONCAT(REPLACE(STR(?part), \".*Q\", \"Q\"), \":\", ?partL) AS ?part_info) }}\n",
    "      OPTIONAL {{ ?company wdt:P127 ?owner . ?owner rdfs:label ?ownerL . FILTER(LANG(?ownerL) = \"en\") BIND(CONCAT(REPLACE(STR(?owner), \".*Q\", \"Q\"), \":\", ?ownerL) AS ?owner_info) }}\n",
    "\n",
    "      SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"en\". }}\n",
    "    }}\n",
    "    GROUP BY ?reqId ?company ?companyLabel ?isin ?foundingYear\n",
    "    \"\"\"\n",
    "    \n",
    "    headers = {'User-Agent': 'PortfolioBot/1.0 (contact: deine-mail@beispiel.de)', 'Accept': 'application/sparql-results+json'}\n",
    "    try:\n",
    "        response = requests.post(url, data={'query': query, 'format': 'json'}, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        \n",
    "        parsed_results = []\n",
    "        for item in data['results']['bindings']:\n",
    "            # Hilfsfunktion zum Trennen von QID und Label\n",
    "            def split_combined(val):\n",
    "                if not val: return \"\", \"\"\n",
    "                parts = val.split('|')\n",
    "                qids = [p.split(':', 1)[0] for p in parts if ':' in p]\n",
    "                labels = [p.split(':', 1)[1] for p in parts if ':' in p]\n",
    "                return \"|\".join(labels), \"|\".join(qids)\n",
    "\n",
    "            res = {\n",
    "                'requested_id': item.get('reqId', {}).get('value'),\n",
    "                'company_qid': item.get('company', {}).get('value').split('/')[-1],\n",
    "                'name': item.get('companyLabel', {}).get('value'),\n",
    "                'isin': item.get('isin', {}).get('value'),\n",
    "                'founding_year': item.get('foundingYear', {}).get('value')\n",
    "            }\n",
    "            \n",
    "            # Mapping der kombinierten Felder zurück in separate Spalten\n",
    "            res['subsidiaries'], res['subsidiary_qids'] = split_combined(item.get('subs_combined', {}).get('value'))\n",
    "            res['industries'], res['industry_qids'] = split_combined(item.get('inds_combined', {}).get('value'))\n",
    "            res['investments'], res['investment_qids'] = split_combined(item.get('invs_combined', {}).get('value'))\n",
    "            res['products'], res['product_qids'] = split_combined(item.get('prods_combined', {}).get('value'))\n",
    "            res['operating_areas'], res['operating_area_qids'] = split_combined(item.get('areas_combined', {}).get('value'))\n",
    "            res['locations'], res['location_qids'] = split_combined(item.get('locs_combined', {}).get('value'))\n",
    "            res['instances'], res['instance_qids'] = split_combined(item.get('insts_combined', {}).get('value'))\n",
    "            res['parts_of'], res['part_of_qids'] = split_combined(item.get('parts_combined', {}).get('value'))\n",
    "            res['owners'], res['owner_qids'] = split_combined(item.get('owners_combined', {}).get('value'))\n",
    "            \n",
    "            parsed_results.append(res)\n",
    "        return parsed_results\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler im Modus {mode}: {e}\")\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d51cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookup_logic = \"?company wdt:P946 ?reqId . BIND(?reqId AS ?isin)\"\n",
    "lookup_logic = f\"?company p:P414 [ ps:P414 wd:{batch[1]} ; pq:P249 ?reqId ] . OPTIONAL {{ ?company wdt:P946 ?isin . }}\"\n",
    "def FetchWikiData(self, batch, url='https://query.wikidata.org/sparql'):\n",
    "        if batch[0] == \"ISIN\":\n",
    "            values_formatted = ' '.join([f'\"{i}\"' for i in batch[2]['ISIN']])\n",
    "            lookup_logic = \"\"\"OPTIONAL { ?company wdt:P946 ?reqId . } BIND(?reqId AS ?isin)\"\"\"\n",
    "        else:\n",
    "            values_formatted = ' '.join([f'\"{t}\"' for t in batch[2]['OriginalTicker']])\n",
    "            lookup_logic = f\"\"\"OPTIONAL {{ ?company p:P414 [ ps:P414 wd:{batch[1]} ; pq:P249 ?reqId ] . }} OPTIONAL {{ ?company wdt:P946 ?isin . }}\"\"\"\n",
    "        query = f\"\"\"\n",
    "        SELECT ?reqId ?company ?companyLabel ?isin ?foundingYear\n",
    "        (GROUP_CONCAT(DISTINCT ?subLabel; separator=\"|\") AS ?subsidiaries)\n",
    "        (GROUP_CONCAT(DISTINCT ?subID; separator=\"|\") AS ?subsidiary_IDs)\n",
    "        (GROUP_CONCAT(DISTINCT ?indLabel; separator=\"|\") AS ?industries)\n",
    "        (GROUP_CONCAT(DISTINCT ?indID; separator=\"|\") AS ?industry_IDs)\n",
    "        (GROUP_CONCAT(DISTINCT ?compLabel; separator=\"|\") AS ?competitors)\n",
    "        (GROUP_CONCAT(DISTINCT ?compID; separator=\"|\") AS ?competitor_IDs)\n",
    "        (GROUP_CONCAT(DISTINCT ?invLabel; separator=\"|\") AS ?investments)\n",
    "        (GROUP_CONCAT(DISTINCT ?invID; separator=\"|\") AS ?investment_IDs)\n",
    "        (GROUP_CONCAT(DISTINCT ?prodLabel; separator=\"|\") AS ?products)\n",
    "        (GROUP_CONCAT(DISTINCT ?prodID; separator=\"|\") AS ?product_IDs)\n",
    "        (GROUP_CONCAT(DISTINCT ?areaLabel; separator=\"|\") AS ?operating_areas)\n",
    "        (GROUP_CONCAT(DISTINCT ?areaID; separator=\"|\") AS ?operating_area_IDs)\n",
    "        (GROUP_CONCAT(DISTINCT ?locLabel; separator=\"|\") AS ?locations)\n",
    "        (GROUP_CONCAT(DISTINCT ?locID; separator=\"|\") AS ?location_IDs)\n",
    "        (GROUP_CONCAT(DISTINCT ?instLabel; separator=\"|\") AS ?instances)\n",
    "        (GROUP_CONCAT(DISTINCT ?instID; separator=\"|\") AS ?instance_IDs)\n",
    "        (GROUP_CONCAT(DISTINCT ?partLabel; separator=\"|\") AS ?parts_of)\n",
    "        (GROUP_CONCAT(DISTINCT ?partID; separator=\"|\") AS ?part_of_IDs)\n",
    "        (GROUP_CONCAT(DISTINCT ?ownerLabel; separator=\"|\") AS ?owners)\n",
    "        (GROUP_CONCAT(DISTINCT ?ownerID; separator=\"|\") AS ?owned_by_IDs)\n",
    "        \n",
    "        WHERE {{\n",
    "        VALUES ?reqId {{ {values_formatted} }}\n",
    "        {lookup_logic}\n",
    "        \n",
    "        OPTIONAL {{ ?company wdt:P571 ?fDate . BIND(YEAR(?fDate) AS ?foundingYear) }}\n",
    "        \n",
    "        # Tochtergesellschaften (P355) & Unternehmensbeteiligungen (P1830)\n",
    "        OPTIONAL {{ \n",
    "            ?company (wdt:P355) ?sub . ?sub rdfs:label ?subLabel . FILTER(LANG(?subLabel) = \"en\") \n",
    "            BIND(REPLACE(STR(?sub), \".*Q\", \"Q\") AS ?subID)\n",
    "        }}\n",
    "        # Beteiligungen (Investments)\n",
    "        OPTIONAL {{ \n",
    "            ?company (wdt:P1830) ?inv . ?inv rdfs:label ?invLabel . FILTER(LANG(?invLabel) = \"en\") \n",
    "            BIND(REPLACE(STR(?inv), \".*Q\", \"Q\") AS ?invID)\n",
    "        }}\n",
    "        # Industrien (P452)\n",
    "        OPTIONAL {{ \n",
    "            ?company wdt:P452 ?ind . ?ind rdfs:label ?indLabel . FILTER(LANG(?indLabel) = \"en\") \n",
    "            BIND(REPLACE(STR(?ind), \".*Q\", \"Q\") AS ?indID)\n",
    "        }}\n",
    "        # Produkte / Material Produced (P1056)\n",
    "        OPTIONAL {{ \n",
    "            ?company wdt:P1056 ?prod . ?prod rdfs:label ?prodLabel . FILTER(LANG(?prodLabel) = \"en\") \n",
    "            BIND(REPLACE(STR(?prod), \".*Q\", \"Q\") AS ?prodID)\n",
    "        }}\n",
    "        # Operating Area (P2541)\n",
    "        OPTIONAL {{ \n",
    "            ?company wdt:P2541 ?area . ?area rdfs:label ?areaLabel . FILTER(LANG(?areaLabel) = \"en\") \n",
    "            BIND(REPLACE(STR(?area), \".*Q\", \"Q\") AS ?areaID)\n",
    "        }}\n",
    "        # Location (P276)\n",
    "        OPTIONAL {{ \n",
    "            ?company wdt:P276 ?loc . ?loc rdfs:label ?locLabel . FILTER(LANG(?locLabel) = \"en\") \n",
    "            BIND(REPLACE(STR(?loc), \".*Q\", \"Q\") AS ?locID)\n",
    "        }}\n",
    "        # Instance of (P31)\n",
    "        OPTIONAL {{ \n",
    "            ?company wdt:P31 ?inst . ?inst rdfs:label ?instLabel . FILTER(LANG(?instLabel) = \"en\") \n",
    "            BIND(REPLACE(STR(?inst), \".*Q\", \"Q\") AS ?instID) \n",
    "        }}\n",
    "        # Part of (P361)\n",
    "        OPTIONAL {{ \n",
    "            ?company wdt:P361 ?part . ?part rdfs:label ?partLabel . FILTER(LANG(?partLabel) = \"en\") \n",
    "            BIND(REPLACE(STR(?part), \".*Q\", \"Q\") AS ?partID)\n",
    "        }}\n",
    "        # Owned by (P127)\n",
    "        OPTIONAL {{ \n",
    "            ?company wdt:P127 ?owner . ?owner rdfs:label ?ownerLabel . FILTER(LANG(?ownerLabel) = \"en\") \n",
    "            BIND(REPLACE(STR(?owner), \".*Q\", \"Q\") AS ?ownerID)\n",
    "        }}\n",
    "\n",
    "        SERVICE wikibase:label {{ bd:serviceParam wikibase:language \"en,fr,de,it\". }}\n",
    "        }}\n",
    "        GROUP BY ?reqId ?company ?companyLabel ?isin ?foundingYear\n",
    "        \"\"\"\n",
    "        headers = {'User-Agent': 'PortfolioBot/1.0', 'Accept': 'application/sparql-results+json'}\n",
    "        print(query)\n",
    "        try:\n",
    "            response = requests.post(url, data={'query': query, 'format': 'json'}, headers=headers)\n",
    "            response.raise_for_status()\n",
    "            data = response.json()\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler für Kriterium {batch[0]} , QID {batch[1]}: {e}\")\n",
    "            return []\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9555b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    def WikiDataQID(self, batches):\n",
    "        all_batches_results = [] # Die Liste, die am Ende Batches enthält\n",
    "        \n",
    "        for batch in batches:\n",
    "            current_batch_list = [] # Hier sammeln wir die Dicts NUR für diesen einen Batch\n",
    "            \n",
    "            if batch[0] == \"ISIN\":\n",
    "                values_formatted = ' '.join([f'\"{i}\"' for i in batch[2]['ISIN']])\n",
    "                query = f\"\"\"SELECT ?reqId ?company WHERE {{ VALUES ?reqId {{ {values_formatted} }} OPTIONAL {{ ?company wdt:P946 ?reqId . }} }}\"\"\"\n",
    "                data = self.InvokeWikiData(query)         \n",
    "                results = data['results']['bindings']\n",
    "                \n",
    "                for result in results:\n",
    "                    reqId = result['reqId']['value']\n",
    "                    company = result.get('company', {}).get('value', None)\n",
    "                    company_qid = company.split('/')[-1] if company else None\n",
    "                    # Hinzufügen zum aktuellen Batch\n",
    "                    current_batch_list.append({\"RequestID\": reqId, \"Company_QID\": company_qid})\n",
    "            \n",
    "            elif batch[0] == 'Ticker':\n",
    "                tickers_formatted = ' '.join([f'\"{i}\"' for i in batch[2]['OriginalTicker']])\n",
    "                query = f\"\"\"SELECT ?reqId ?company WHERE {{ VALUES ?reqId {{ {tickers_formatted} }} OPTIONAL {{ ?company p:P414 [ ps:P414 wd:{batch[1]} ; pq:P249 ?reqId ] . }} }}\"\"\"\n",
    "                data = self.InvokeWikiData(query)         \n",
    "                results = data['results']['bindings']\n",
    "                \n",
    "                for result in results:\n",
    "                    reqId = result['reqId']['value']\n",
    "                    company = result.get('company', {}).get('value', None)\n",
    "                    company_qid = company.split('/')[-1] if company else None\n",
    "                    # Hinzufügen zum aktuellen Batch\n",
    "                    current_batch_list.append({\"RequestID\": reqId, \"Company_QID\": company_qid})\n",
    "            \n",
    "            # WICHTIG: Den fertigen Batch der Hauptliste hinzufügen\n",
    "            if current_batch_list:\n",
    "                all_batches_results.append(current_batch_list)\n",
    "                \n",
    "        return all_batches_results\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f02584f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WikiData:\n",
    "    def __init__(self, tickers):\n",
    "        self.tickers = tickers\n",
    "        self.url = \"https://query.wikidata.org/sparql\"\n",
    "        self.session = requests.Session()\n",
    "        self.session.headers.update({\n",
    "            \"User-Agent\": \"PortfolioBot/1.0 (contact: your-email@example.com)\",\n",
    "            \"Accept\": \"text/csv\",\n",
    "        })\n",
    "\n",
    "    def batching(self, batch_size: int = 20):\n",
    "        self.tickers.sort_values(\"Exchange_QID\", inplace=True)\n",
    "        batches = []\n",
    "        for qid, df in self.tickers.groupby(\"Exchange_QID\", sort=False):\n",
    "            isin_series = df[\"ISIN\"].astype(\"string\").str.strip()\n",
    "            has_isin = isin_series.notna() & (isin_series != \"\")\n",
    "\n",
    "            isin_df = df.loc[has_isin]\n",
    "            tkr_df  = df.loc[~has_isin]\n",
    "\n",
    "            for i in range(0, len(isin_df), batch_size):\n",
    "                batches.append((\"ISIN\", qid, isin_df.iloc[i:i + batch_size]))\n",
    "\n",
    "            for i in range(0, len(tkr_df), batch_size):\n",
    "                batches.append((\"Ticker\", qid, tkr_df.iloc[i:i + batch_size]))\n",
    "        print(\"Batching completed\")\n",
    "        return batches\n",
    "    \n",
    "    def InvokeWikiData(self, query, timeout=40, max_retries=3):\n",
    "        url = \"https://query.wikidata.org/sparql\"\n",
    "        headers = {\n",
    "            \"User-Agent\": \"PortfolioBot/1.0 (contact: your-email@example.com)\",\n",
    "            \"Accept\": \"text/csv\",\n",
    "        }\n",
    "\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                response = self.session.get(self.url, params={\"query\": query}, timeout=timeout)\n",
    "                '''\n",
    "                response = requests.get(\n",
    "                    url,\n",
    "                    params={\"query\": query},\n",
    "                    headers=headers,\n",
    "                    timeout=timeout\n",
    "                )\n",
    "                '''\n",
    "                response.raise_for_status()\n",
    "\n",
    "                ctype = response.headers.get(\"Content-Type\", \"\")\n",
    "                text = response.text\n",
    "\n",
    "                # Wenn kein CSV zurückkommt, sondern HTML/Fehlertext:\n",
    "                if \"text/csv\" not in ctype and not text.lstrip().startswith((\"?\", '\"')):\n",
    "                    # Debug-Ausgabe\n",
    "                    print(\"Non-CSV response:\", ctype)\n",
    "                    print(text[:300])\n",
    "                    return None\n",
    "\n",
    "                # CSV robust lesen\n",
    "                return pd.read_csv(\n",
    "                    StringIO(text),\n",
    "                    sep=\",\",            # Wikidata CSV ist i.d.R. comma\n",
    "                    engine=\"python\",    # python-engine ist toleranter als C-engine\n",
    "                )\n",
    "            \n",
    "\n",
    "            except requests.exceptions.Timeout:\n",
    "                print(f\"Timeout (attempt {attempt+1}/{max_retries})\")\n",
    "                time.sleep(2 * (attempt + 1))\n",
    "            except pd.errors.ParserError as e:\n",
    "                print(\"CSV ParserError:\", e)\n",
    "                print(\"Response head:\\n\", response.text[:500])\n",
    "                return None\n",
    "            except Exception as e:\n",
    "                print(\"Request error:\", e)\n",
    "                return None\n",
    "\n",
    "        return None\n",
    "            \n",
    "    def WikiDataQID(self, batches):\n",
    "        batch_list = []\n",
    "        count = 1\n",
    "        for batch in batches:\n",
    "            print(\"Batch = \", count)\n",
    "            count += 1\n",
    "            if batch[0] == \"ISIN\":\n",
    "                values_formatted = \" \".join(f'\"{i}\"' for i in batch[2][\"ISIN\"])\n",
    "                query = f\"\"\"\n",
    "                SELECT ?reqId ?company WHERE {{\n",
    "                VALUES ?reqId {{ {values_formatted} }}\n",
    "                OPTIONAL {{ ?company wdt:P946 ?reqId . }}\n",
    "                }}\n",
    "                \"\"\"\n",
    "                df = self.InvokeWikiData(query)\n",
    "                \n",
    "                if df is None or df.empty:\n",
    "                    continue\n",
    "\n",
    "                # company URI -> QID\n",
    "                if \"company\" in df.columns:\n",
    "                    df[\"Company_QID\"] = df[\"company\"].astype(str).str.rsplit(\"/\", n=1).str[-1]\n",
    "                else:\n",
    "                    df[\"Company_QID\"] = None\n",
    "\n",
    "                df.drop(columns=['company'], inplace=True, errors='ignore')\n",
    "                batch_list.append(df)\n",
    "\n",
    "            elif batch[0] == \"Ticker\":\n",
    "                tickers_formatted = \" \".join(f'\"{i}\"' for i in batch[2][\"OriginalTicker\"])\n",
    "                query = f\"\"\"\n",
    "                SELECT ?reqId ?company WHERE {{\n",
    "                VALUES ?reqId {{ {tickers_formatted} }}\n",
    "                OPTIONAL {{ ?company p:P414 [ ps:P414 wd:{batch[1]} ; pq:P249 ?reqId ] . }}\n",
    "                }}\n",
    "                \"\"\"\n",
    "                df = self.InvokeWikiData(query)\n",
    "                if df is None or df.empty:\n",
    "                    continue\n",
    "                if \"company\" in df.columns:\n",
    "                    df[\"Company_QID\"] = df[\"company\"].astype(str).str.rsplit(\"/\", n=1).str[-1]\n",
    "                else:\n",
    "                    df[\"Company_QID\"] = None\n",
    "                \n",
    "                df.drop(columns=['company'], inplace=True, errors='ignore')\n",
    "                batch_list.append(df)\n",
    "        print(\"Fetching Company_QID completed\")\n",
    "        return batch_list\n",
    "        \n",
    "    def FetchInfo(self, batch: pd.DataFrame):\n",
    "        results_per_query = []\n",
    "        batch = batch[batch[\"Company_QID\"] != 'nan']\n",
    "        qids = \" \".join(f\"wd:{q}\" for q in batch[\"Company_QID\"])\n",
    "        for query_name, template in WIKIDATA_QUERIES.items():\n",
    "            query = template.replace(\"__VALUES__\", qids)  # <-- wichtig\n",
    "            df = self.InvokeWikiData(query)\n",
    "            if df is None or df.empty:\n",
    "                    continue\n",
    "            if \"company\" in df.columns:\n",
    "                df[\"Company_QID\"] = df[\"company\"].astype(str).str.rsplit(\"/\", n=1).str[-1]\n",
    "            else:\n",
    "                df[\"Company_QID\"] = None\n",
    "            df.drop(columns=['company'], inplace=True, errors='ignore')\n",
    "            results_per_query.append(df)\n",
    "        return results_per_query\n",
    "    \n",
    "    def merge_querys(self, list_of_query: pd.DataFrame):\n",
    "        list_to_concat = []\n",
    "        for batch in list_of_query:\n",
    "            for query in batch:\n",
    "                oldname = query.columns[0]\n",
    "                query = query.rename(columns={oldname: \"Value\"})\n",
    "                query['Item_Description'] = oldname\n",
    "                query = query[['Company_QID', 'Item_Description', 'Value']]\n",
    "                list_to_concat.append(query)\n",
    "        return pd.concat(list_to_concat, ignore_index=True)  \n",
    "    \n",
    "    def join_reference(self, batch_list, data):\n",
    "        ref = pd.concat(batch_list)\n",
    "        df_merged = data.merge(\n",
    "        ref[[\"Company_QID\", \"reqId\"]],\n",
    "        on=\"Company_QID\",\n",
    "        how=\"left\"\n",
    "        )\n",
    "        return df_merged\n",
    "\n",
    "    def run(self):\n",
    "        list_of_results = []\n",
    "        batches = self.batching()\n",
    "        #batches = batches[:10]\n",
    "        company_qid = self.WikiDataQID(batches)\n",
    "        for batch in company_qid:\n",
    "            result = self.FetchInfo(batch)\n",
    "            list_of_results.append(result)\n",
    "            data = self.merge_querys(list_of_results)\n",
    "            joined = self.join_reference(company_qid, data)\n",
    "        return joined[['reqId', 'Company_QID', 'Item_Description', 'Value']].sort_values(\"reqId\")\n",
    "        \n",
    "#test = pd.read_csv(\"C:\\\\Diversification\\\\data\\\\tickers.csv\")\n",
    "#WikiData(test).run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeed69f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WikiDataClient:\n",
    "    def batching(self, tickers, batch_size: int = 100):\n",
    "        tickers.sort_values(\"Exchange_QID\", inplace=True)\n",
    "        batches = []\n",
    "        for qid, df in tickers.groupby(\"Exchange_QID\", sort=False):\n",
    "            isin_series = df[\"ISIN\"].astype(\"string\").str.strip()\n",
    "            has_isin = isin_series.notna() & (isin_series != \"\")\n",
    "\n",
    "            isin_df = df.loc[has_isin]\n",
    "            tkr_df  = df.loc[~has_isin]\n",
    "\n",
    "            for i in range(0, len(isin_df), batch_size):\n",
    "                batches.append((\"ISIN\", qid, isin_df.iloc[i:i + batch_size]))\n",
    "\n",
    "            for i in range(0, len(tkr_df), batch_size):\n",
    "                batches.append((\"Ticker\", qid, tkr_df.iloc[i:i + batch_size]))\n",
    "\n",
    "        return batches \n",
    "    \n",
    "    def QIDBatching(self, qids, batch_size: int = 100):\n",
    "        QID_batches = []\n",
    "        for i in range(0, len(qids), batch_size):\n",
    "            QID_batches.append(qids[i:i + batch_size])\n",
    "        return QID_batches\n",
    "\n",
    "    def InvokeWikiData(self, query):\n",
    "        url = \"https://query.wikidata.org/sparql\"\n",
    "        headers = {\n",
    "            \"User-Agent\": \"PortfolioBot/1.0 (contact: your-email@example.com)\",\n",
    "            \"Accept\": \"application/sparql-results+json\"\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            response = requests.get(\n",
    "                url,\n",
    "                params={\"query\": query, \"format\": \"json\"},\n",
    "                headers=headers,\n",
    "                timeout=30\n",
    "            )\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler bei der Anfrage: {e}\")\n",
    "            return None\n",
    "\n",
    "    def WikiDataQID(self, batches, url='https://query.wikidata.org/sparql'):\n",
    "        list_of_dicts = []\n",
    "        for batch in batches:\n",
    "            if batch[0] == \"ISIN\":\n",
    "                values_formatted = ' '.join([f'\"{i}\"' for i in batch[2]['ISIN']])\n",
    "                query = f\"\"\"SELECT ?reqId ?company WHERE {{ VALUES ?reqId {{ {values_formatted} }} OPTIONAL {{ ?company wdt:P946 ?reqId . }} }}\"\"\"\n",
    "                data = self.InvokeWikiData(query)         \n",
    "                results = data['results']['bindings']\n",
    "                for result in results:\n",
    "                    reqId = result['reqId']['value']\n",
    "                    company = result.get('company', {}).get('value', None)\n",
    "                    if company is not None and company != \"\":\n",
    "                        company_qid = company.split('/')[-1]\n",
    "                    list_of_dicts.append({\"RequestID\": reqId, \"Company_QID\": company_qid if company is not None else None})\n",
    "\n",
    "                \n",
    "            elif batch[0] == 'Ticker':\n",
    "                tickers_formatted = ' '.join([f'\"{i}\"' for i in batch[2]['OriginalTicker']])\n",
    "                query = f\"\"\"\n",
    "                SELECT ?reqId ?company ?companyLabel\n",
    "                WHERE {{\n",
    "                VALUES ?reqId {{ {tickers_formatted} }}\n",
    "\n",
    "                OPTIONAL {{\n",
    "                    ?company p:P414 [\n",
    "                    ps:P414 wd:{batch[1]} ;\n",
    "                    pq:P249 ?reqId\n",
    "                    ] .\n",
    "                }}\n",
    "\n",
    "                SERVICE wikibase:label {{\n",
    "                    bd:serviceParam wikibase:language \"en\".\n",
    "                }}\n",
    "                }}\n",
    "                \"\"\"                    \n",
    "\n",
    "                data = self.InvokeWikiData(query)         \n",
    "                results = data['results']['bindings']\n",
    "                for result in results:\n",
    "                    reqId = result['reqId']['value']\n",
    "                    company = result.get('company', {}).get('value', None)\n",
    "                    if company is not None and company != \"\":\n",
    "                        company_qid = company.split('/')[-1]\n",
    "                    list_of_dicts.append({\"RequestID\": reqId, \"Company_QID\": company_qid if company is not None else None})\n",
    "        \n",
    "        return list_of_dicts\n",
    "    \n",
    "    def WikiDataSubsidiaries(self, company_qids_batches):\n",
    "        list_of_dicts = []\n",
    "        for batch in company_qids_batches:\n",
    "            qids_formatted = ' '.join([f'wd:{qid}' for qid in batch])\n",
    "            query = f\"\"\"\n",
    "            SELECT ?parentCompany ?subsidiaryCompany\n",
    "            WHERE {{\n",
    "                VALUES ?parentCompany {{ {qids_formatted} }}\n",
    "                ?subsidiaryCompany wdt:P355 ?parentCompany .\n",
    "            }}\n",
    "            \"\"\"\n",
    "            data = self.InvokeWikiData(query)         \n",
    "            results = data['results']['bindings']\n",
    "            for result in results:\n",
    "                parent_company = result['parentCompany']['value']\n",
    "                subsidiary_company = result['subsidiaryCompany']['value']\n",
    "                parent_qid = parent_company.split('/')[-1]\n",
    "                subsidiary_qid = subsidiary_company.split('/')[-1]\n",
    "                list_of_dicts.append({\"Parent_Company_QID\": parent_qid, \"Subsidiary_Company_QID\": subsidiary_qid})\n",
    "        return list_of_dicts\n",
    "\n",
    "\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
