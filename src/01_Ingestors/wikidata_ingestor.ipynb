{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a12d5f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "import importlib, wikidata_queries\n",
    "importlib.reload(wikidata_queries)\n",
    "from wikidata_queries import WIKIDATA_QUERIES  # erneut ausführen\n",
    "import requests\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17d60680",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Retryable(Exception):\n",
    "    pass\n",
    "\n",
    "class Abort(Exception):\n",
    "    pass\n",
    "class WikiDataClient():\n",
    "    def __init__(self):\n",
    "        self.url = \"https://query.wikidata.org/sparql\"\n",
    "        self.session = requests.Session()\n",
    "        self.session.headers.update({\"User-Agent\": \"PortfolioBot/1.0 (contact: your-email@example.com)\", \"Accept\": \"text/csv\",})\n",
    "        self.max_retries = 3\n",
    "        self.timeout = 30\n",
    "        self.retry_statuses = (429, 500, 502, 503, 504)\n",
    "    \n",
    "    def request(self, query):\n",
    "        return self.session.get(self.url, params={\"query\": query}, timeout=self.timeout)\n",
    "\n",
    "    def validate_format(self, response) -> None:\n",
    "        ctype = (response.headers.get(\"Content-Type\") or \"\").lower()\n",
    "        text = response.text or \"\"\n",
    "\n",
    "        is_csv_header = \"text/csv\" in ctype\n",
    "        looks_like_csv = text.lstrip().startswith(('\"', '?'))  # heuristik\n",
    "\n",
    "        if not is_csv_header and not looks_like_csv:\n",
    "            raise ValueError(f\"Non-CSV response. ctype={ctype}. head={text[:200]}\")\n",
    "\n",
    "    def parse_df(self, response) -> pd.DataFrame:\n",
    "        text = response.text or \"\"\n",
    "        return pd.read_csv(StringIO(text), sep=\",\", engine=\"python\")\n",
    "    \n",
    "    def _check_status(self, response):\n",
    "        retryable = {429, 500, 502, 503, 504}\n",
    "        status = response.status_code\n",
    "\n",
    "        if status in (400, 404):\n",
    "            raise Abort(f\"Non-retryable HTTP {status}: {response.text[:200]}\")\n",
    "\n",
    "        if 400 <= status < 500 and status != 429:\n",
    "            raise Abort(f\"Non-retryable client error HTTP {status}: {response.text[:200]}\")\n",
    "\n",
    "        if status in retryable:\n",
    "            raise Retryable(f\"Retryable HTTP {status}: {response.text[:200]}\")\n",
    "\n",
    "        if 500 <= status < 600:\n",
    "            raise Retryable(f\"Server error HTTP {status}: {response.text[:200]}\")\n",
    "\n",
    "    def _attempt(self, query):\n",
    "        response = self.request(query)              # kann Timeout/ConnectionError werfen\n",
    "        self._check_status(response)                # kann Retryable/Abort werfen\n",
    "\n",
    "        try:\n",
    "            self.validate_format(response)          # kann ValueError werfen\n",
    "            return self.parse_df(response)          # kann ParserError werfen\n",
    "        except ValueError as e:\n",
    "            raise Retryable(f\"Format invalid: {e}\") from e\n",
    "        except pd.errors.ParserError as e:\n",
    "            raise Retryable(f\"CSV ParserError: {e}\") from e\n",
    "    \n",
    "    def invoke_retry(self, query):\n",
    "        for attempt in range(self.max_retries):\n",
    "            try:\n",
    "                return self._attempt(query)\n",
    "        \n",
    "            except (requests.exceptions.Timeout, requests.exceptions.ConnectionError) as e:\n",
    "                print(f\"Attempt {attempt+1} network failed:\", e)\n",
    "                time.sleep(min(30, 2 ** attempt))\n",
    "                continue\n",
    "        \n",
    "            except Retryable as e:\n",
    "                print(f\"Attempt {attempt+1} retryable:\", e)\n",
    "                time.sleep(5)\n",
    "                continue\n",
    "\n",
    "            except Abort as e:\n",
    "                print(f\"Abort:\", e)\n",
    "                return None\n",
    "\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08c2efa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WikiDataQueryBuilder:\n",
    "   def __init__(self):\n",
    "      self.templates = WIKIDATA_QUERIES\n",
    "   def formatting_request_id(self, tickers):\n",
    "      return \" \".join(f'\"{i}\"' for i in tickers)\n",
    "   def formatting_company_qid(self, qids):\n",
    "      return \" \".join(f'wd:{i}' for i in qids)\n",
    "   def build_company_by_isin(self, isin):\n",
    "      isin_formatted = \" \".join(f'\"{i}\"' for i in isin)\n",
    "      query = f\"\"\"SELECT ?reqId ?company WHERE {{VALUES ?reqId {{ {isin_formatted} }} OPTIONAL {{ ?company wdt:P946 ?reqId . }}}}\"\"\"\n",
    "      return query\n",
    "   def build_company_by_ticker(self, exchange_qid, tickers):\n",
    "      tickers_formatted = self.formatting_request_id(tickers)\n",
    "      query = f\"\"\"SELECT ?reqId ?company WHERE {{VALUES ?reqId {{ {tickers_formatted} }} OPTIONAL {{ ?company p:P414 [ ps:P414 wd:{exchange_qid} ; pq:P249 ?reqId ] . }}}}\"\"\"\n",
    "      return query\n",
    "   def build_features_by_qid(self, qids, feature_name):\n",
    "      formatted_qids = self.formatting_company_qid(qids)\n",
    "      feature_template = self.templates[feature_name]\n",
    "      query = feature_template.replace(\"__VALUES__\", formatted_qids)\n",
    "      return query\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3880506",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WikiDataTransformer:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    import pandas as pd\n",
    "\n",
    "    def wikidata_uri_to_qid_df(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        df = df.copy()\n",
    "\n",
    "        def convert_cell(x):\n",
    "            # NaN/NaT unverändert\n",
    "            if pd.isna(x):\n",
    "                return x\n",
    "            # nur Strings prüfen\n",
    "            if not isinstance(x, str):\n",
    "                return x\n",
    "\n",
    "            s = x.strip()\n",
    "            # nur echte Wikidata Entity-URIs konvertieren\n",
    "            prefix = \"http://www.wikidata.org/entity/\"\n",
    "            prefix2 = \"https://www.wikidata.org/entity/\"\n",
    "            if s.startswith(prefix):\n",
    "                return s[len(prefix):]\n",
    "            if s.startswith(prefix2):\n",
    "                return s[len(prefix2):]\n",
    "            return x\n",
    "\n",
    "        return df.applymap(convert_cell)\n",
    "\n",
    "    def extract_qids(self, df):\n",
    "        uris = df.copy()\n",
    "        uris['Company_QID'] = uris['company'].astype(str).str.rsplit(\"/\", n=1).str[-1]\n",
    "        return uris.drop(columns=[\"company\"])\n",
    "    def transform_qid(self, qid_batch):\n",
    "        no_nan_qid_batch = qid_batch.dropna()\n",
    "        return self.extract_qids(no_nan_qid_batch)\n",
    "    def stack_long_dfs(self, dfs, id_col=\"company\"):\n",
    "        out = []\n",
    "        for df in dfs:\n",
    "            value_cols = [c for c in df.columns if c != id_col]\n",
    "            if len(value_cols) != 1:\n",
    "                raise ValueError(f\"Expected exactly 1 value col besides {id_col}, got {value_cols}\")\n",
    "            value_col = value_cols[0]\n",
    "            tmp = df.rename(columns={value_col: \"Value\"}).copy()\n",
    "            tmp[\"Item_Description\"] = value_col\n",
    "            out.append(tmp[[id_col, \"Item_Description\", \"Value\"]])\n",
    "        return pd.concat(out, ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12150209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 retryable: Retryable HTTP 429: \n"
     ]
    }
   ],
   "source": [
    "class WikiDataIngestor:\n",
    "    def __init__(self):\n",
    "        self.client = WikiDataClient()\n",
    "        self.builder = WikiDataQueryBuilder()\n",
    "        self.transformer = WikiDataTransformer()\n",
    "        self.features_to_fetch = WIKIDATA_QUERIES.keys()\n",
    "\n",
    "    def batching_for_qid(self, tickerlist, batch_size=20):\n",
    "        required_cols = ['OriginalTicker', 'YahooTicker', 'Exchange_QID', 'ISIN']\n",
    "        missing = [c for c in required_cols if c not in tickerlist.columns]\n",
    "        if missing:\n",
    "            raise ValueError(f\"tickerlist missing required columns: {missing}\")\n",
    "        batches = []\n",
    "        df_all = tickerlist.copy()\n",
    "\n",
    "        for exchange_qid, df in df_all.groupby(\"Exchange_QID\", sort=True):\n",
    "            isin_series = df[\"ISIN\"].astype(\"string\").str.strip()\n",
    "            has_isin = isin_series.notna() & (isin_series != \"\")\n",
    "\n",
    "            # --- ISIN batches ---\n",
    "            isin_vals = isin_series.loc[has_isin].dropna().astype(str).str.strip()\n",
    "            isin_vals = [v for v in isin_vals.tolist() if v]  # remove empty\n",
    "            # stable dedup\n",
    "            isin_vals = list(dict.fromkeys(isin_vals))\n",
    "\n",
    "            for i in range(0, len(isin_vals), batch_size):\n",
    "                batches.append((\"ISIN\", None, isin_vals[i:i + batch_size]))\n",
    "\n",
    "            # --- Ticker batches ---\n",
    "            tkr_series = df.loc[~has_isin, \"OriginalTicker\"].astype(\"string\").str.strip()\n",
    "            tkr_vals = [v for v in tkr_series.dropna().astype(str).tolist() if v]\n",
    "            tkr_vals = list(dict.fromkeys(tkr_vals))\n",
    "\n",
    "            for i in range(0, len(tkr_vals), batch_size):\n",
    "                batches.append((\"TICKER\", str(exchange_qid), tkr_vals[i:i + batch_size]))\n",
    "\n",
    "        return batches\n",
    "    def batching_for_features(self, qids, batch_size = 10):\n",
    "        batches = []\n",
    "        for i in range(0,len(qids), batch_size):\n",
    "            batches.append(qids[i:i+batch_size])\n",
    "        return batches\n",
    "\n",
    "    def get_qids(self, tickerlist):\n",
    "        batches_for_qids = self.batching_for_qid(tickerlist)\n",
    "        qids = []\n",
    "        for batch in batches_for_qids:\n",
    "            if batch[0] == \"TICKER\":\n",
    "                query = self.builder.build_company_by_ticker(batch[1], batch[2])\n",
    "            if batch[0] == \"ISIN\":\n",
    "                query = self.builder.build_company_by_isin(batch[2])\n",
    "            qid = self.client.invoke_retry(query)\n",
    "            qid_batch = self.transformer.transform_qid(qid)\n",
    "            qids.extend(qid_batch['Company_QID'])\n",
    "        return qids\n",
    "    \n",
    "    def get_feature(self, batch, features_to_fetch):\n",
    "        join_list = []\n",
    "        for feature in features_to_fetch:\n",
    "            query = self.builder.build_features_by_qid(batch, feature)\n",
    "            feature_df = self.client.invoke_retry(query)\n",
    "            feature_df = self.transformer.wikidata_uri_to_qid_df(feature_df)\n",
    "            join_list.append(feature_df)\n",
    "        return join_list\n",
    "\n",
    "    def run(self, tickerlist):\n",
    "        list_of_long_batches = []\n",
    "        qids = self.get_qids(tickerlist)\n",
    "        feature_batches = self.batching_for_features(qids)\n",
    "        for batch in feature_batches:\n",
    "            features = self.get_feature(batch, features_to_fetch=self.features_to_fetch)\n",
    "            features_long = self.transformer.stack_long_dfs(features)\n",
    "            list_of_long_batches.append(features_long)\n",
    "        return pd.concat(list_of_long_batches)\n",
    "                \n",
    "\n",
    "test = pd.read_csv(\"C:\\\\Diversification\\\\data\\\\tickers.csv\")\n",
    "df = WikiDataIngestor().run(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b1e7190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36638"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7683ac38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import duckdb\n",
    "class DataHub:\n",
    "    def __init__(self, db_name=\"yahoo_finance.db\"):\n",
    "        # Pfad-Management (funktioniert in Scripts & Notebooks)\n",
    "        base_path = Path.cwd()\n",
    "        db_path = base_path.parent.parent / \"data\" / \"01_raw\" / \"yahoo\" / db_name\n",
    "        db_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Verbindung herstellen\n",
    "        self.con = duckdb.connect(str(db_path))\n",
    "        self._initialize_tables()\n",
    "        print(f\"DuckDB verbunden: {db_path}\")\n",
    "\n",
    "    def _initialize_tables(self):\n",
    "            \"\"\"Erstellt die Tabellenstruktur, falls sie noch nicht existiert.\"\"\"\n",
    "            # Yahoo / Financials\n",
    "            self.con.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS bronze_financials (\n",
    "                    ticker VARCHAR,\n",
    "                    date DATE,\n",
    "                    affiliation VARCHAR,\n",
    "                    item_description VARCHAR,\n",
    "                    value DOUBLE,\n",
    "                    ingested_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "                );\n",
    "            \"\"\")\n",
    "            self.con.execute(\n",
    "                \"CREATE INDEX IF NOT EXISTS idx_ticker_date ON bronze_financials (ticker, date);\"\n",
    "            )\n",
    "\n",
    "            # Wikidata\n",
    "            self.con.execute(\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS bronze_wikidata (\n",
    "                    company_qid VARCHAR,\n",
    "                    item_description VARCHAR,\n",
    "                    value VARCHAR,\n",
    "                    ingested_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "                );\n",
    "            \"\"\")\n",
    "\n",
    "            # Index(e) für schnellere Abfragen\n",
    "            self.con.execute(\n",
    "                \"CREATE INDEX IF NOT EXISTS idx_wikidata_qid ON bronze_wikidata (company_qid);\"\n",
    "            )\n",
    "            self.con.execute(\n",
    "                \"CREATE INDEX IF NOT EXISTS idx_wikidata_qid_item ON bronze_wikidata (company_qid, item_description);\"\n",
    "            )\n",
    "\n",
    "    def insert_financials(self, df: pd.DataFrame):\n",
    "        \"\"\"Speichert ein einheitliches DataFrame in die Datenbank.\"\"\"\n",
    "        if df is None or df.empty:\n",
    "            return\n",
    "\n",
    "        # Wir nutzen den 'Appender' Mechanismus von DuckDB für maximale Speed\n",
    "        # DuckDB erkennt das DataFrame 'df' im lokalen Python-Scope automatisch\n",
    "        try:\n",
    "            self.con.execute(\"INSERT INTO bronze_financials (ticker, date, affiliation, item_description, value) SELECT ticker, date, affiliation, item_description, value FROM df\")\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler beim Insert: {e}\")\n",
    "\n",
    "    def insert_wikidata(self, df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Speichert Wikidata-DataFrame in die Datenbank.\n",
    "        Erwartete Spalten: Company_QID, Item_Description, Value\n",
    "        \"\"\"\n",
    "        if df is None or df.empty:\n",
    "            return\n",
    "\n",
    "        # Defensive: Spalten checken (leicht tolerant bzgl. Case)\n",
    "        required = {\"company\", \"Item_Description\", \"Value\"}\n",
    "        if not required.issubset(set(df.columns)):\n",
    "            missing = required - set(df.columns)\n",
    "            raise ValueError(f\"Wikidata DF fehlt Spalten: {missing}. Vorhanden: {list(df.columns)}\")\n",
    "\n",
    "        # Optional: Leichte Normalisierung/Typ-Sicherheit (Value als string ist am robustesten)\n",
    "        df = df.copy()\n",
    "        df[\"Company_QID\"] = df[\"company\"].astype(str)\n",
    "        df[\"Item_Description\"] = df[\"Item_Description\"].astype(str)\n",
    "        df[\"Value\"] = df[\"Value\"].astype(str)\n",
    "\n",
    "        # In DuckDB-Insert: aliasen auf die Spaltennamen der Tabelle\n",
    "        try:\n",
    "            self.con.execute(\"\"\"\n",
    "                INSERT INTO bronze_wikidata (company_qid, item_description, value)\n",
    "                SELECT\n",
    "                    Company_QID AS company_qid,\n",
    "                    Item_Description AS item_description,\n",
    "                    Value AS value\n",
    "                FROM df\n",
    "            \"\"\")\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler beim Wikidata-Insert: {e}\")\n",
    "\n",
    "    def preview_data(self, table=\"bronze_wikidata\", limit=100):\n",
    "        \"\"\"Holt Einträge als DataFrame zur Kontrolle.\"\"\"\n",
    "        df = self.con.execute(f\"SELECT * FROM {table} LIMIT {int(limit)}\").df()\n",
    "        return df\n",
    "\n",
    "\n",
    "    def get_summary_stats(self):\n",
    "        \"\"\"Gibt eine kleine Statistik über den Füllstand der DB aus.\"\"\"\n",
    "        return self.con.execute(\"\"\"\n",
    "            SELECT \n",
    "                (SELECT COUNT(DISTINCT ticker) FROM bronze_financials) as count_tickers,\n",
    "                (SELECT COUNT(*) FROM bronze_financials) as total_financial_rows,\n",
    "                (SELECT COUNT(DISTINCT company_qid) FROM bronze_wikidata) as count_company_qids,\n",
    "                (SELECT COUNT(*) FROM bronze_wikidata) as total_wikidata_rows\n",
    "        \"\"\").df()\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"Schließt die Verbindung sauber.\"\"\"\n",
    "        self.con.close()\n",
    "\n",
    "    def clear_database(self):\n",
    "        \"\"\"\n",
    "        Löscht alle Daten und Tabellen aus der DuckDB-Datenbank.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            tables = self.con.execute(\"SHOW TABLES\").fetchall()\n",
    "\n",
    "            if not tables:\n",
    "                print(\"Datenbank ist bereits leer.\")\n",
    "                return\n",
    "\n",
    "            print(f\"Lösche {len(tables)} Tabellen...\")\n",
    "\n",
    "            for (table_name,) in tables:\n",
    "                self.con.execute(f\"DROP TABLE IF EXISTS {table_name}\")\n",
    "\n",
    "            print(\"Datenbank wurde erfolgreich geleert.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler beim Leeren der Datenbank: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c9a42cdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DuckDB verbunden: c:\\Diversification\\data\\01_raw\\yahoo\\yahoo_finance.db\n"
     ]
    }
   ],
   "source": [
    "DataHub().insert_wikidata(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e61a292a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DuckDB verbunden: c:\\Diversification\\data\\01_raw\\yahoo\\yahoo_finance.db\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_qid</th>\n",
       "      <th>item_description</th>\n",
       "      <th>value</th>\n",
       "      <th>ingested_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q753684</td>\n",
       "      <td>isin</td>\n",
       "      <td>FR0010478248</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q753684</td>\n",
       "      <td>isin</td>\n",
       "      <td>US4659401040</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q1052675</td>\n",
       "      <td>isin</td>\n",
       "      <td>FR0000053506</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q1375196</td>\n",
       "      <td>isin</td>\n",
       "      <td>FR0010490920</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q2943995</td>\n",
       "      <td>isin</td>\n",
       "      <td>FR0010425595</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Q65158292</td>\n",
       "      <td>isin</td>\n",
       "      <td>FR0011648716</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Q79189910</td>\n",
       "      <td>isin</td>\n",
       "      <td>FR0013341781</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Q98778444</td>\n",
       "      <td>isin</td>\n",
       "      <td>FR0000060840</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Q98931288</td>\n",
       "      <td>isin</td>\n",
       "      <td>FR0000054421</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Q130387411</td>\n",
       "      <td>isin</td>\n",
       "      <td>FR0012819381</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Q131651749</td>\n",
       "      <td>isin</td>\n",
       "      <td>FR001400SVN0</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Q753684</td>\n",
       "      <td>founding_year</td>\n",
       "      <td>1983-06-01T00:00:00Z</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Q1052675</td>\n",
       "      <td>founding_year</td>\n",
       "      <td>1969-01-01T00:00:00Z</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Q1375196</td>\n",
       "      <td>founding_year</td>\n",
       "      <td>2000-09-01T00:00:00Z</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Q2943995</td>\n",
       "      <td>founding_year</td>\n",
       "      <td>1999-01-01T00:00:00Z</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Q65158292</td>\n",
       "      <td>founding_year</td>\n",
       "      <td>2011-01-01T00:00:00Z</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Q79189910</td>\n",
       "      <td>founding_year</td>\n",
       "      <td>2005-01-01T00:00:00Z</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Q98778444</td>\n",
       "      <td>founding_year</td>\n",
       "      <td>1927-01-01T00:00:00Z</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Q98778444</td>\n",
       "      <td>founding_year</td>\n",
       "      <td>1958-01-01T00:00:00Z</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Q98931288</td>\n",
       "      <td>founding_year</td>\n",
       "      <td>1975-01-01T00:00:00Z</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Q130387411</td>\n",
       "      <td>founding_year</td>\n",
       "      <td>1972-01-01T00:00:00Z</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Q131651749</td>\n",
       "      <td>founding_year</td>\n",
       "      <td>2011-04-12T00:00:00Z</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Q753684</td>\n",
       "      <td>subsidiaries</td>\n",
       "      <td>Q527336</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Q753684</td>\n",
       "      <td>subsidiaries</td>\n",
       "      <td>Q15018011</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Q1052675</td>\n",
       "      <td>subsidiaries</td>\n",
       "      <td>nan</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Q1375196</td>\n",
       "      <td>subsidiaries</td>\n",
       "      <td>Q16635235</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Q2943995</td>\n",
       "      <td>subsidiaries</td>\n",
       "      <td>nan</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Q65158292</td>\n",
       "      <td>subsidiaries</td>\n",
       "      <td>nan</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Q79189910</td>\n",
       "      <td>subsidiaries</td>\n",
       "      <td>nan</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Q98778444</td>\n",
       "      <td>subsidiaries</td>\n",
       "      <td>nan</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Q98931288</td>\n",
       "      <td>subsidiaries</td>\n",
       "      <td>Q573356</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Q130387411</td>\n",
       "      <td>subsidiaries</td>\n",
       "      <td>Q126880572</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Q131651749</td>\n",
       "      <td>subsidiaries</td>\n",
       "      <td>nan</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Q753684</td>\n",
       "      <td>investments</td>\n",
       "      <td>Q527336</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Q1052675</td>\n",
       "      <td>investments</td>\n",
       "      <td>nan</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Q1375196</td>\n",
       "      <td>investments</td>\n",
       "      <td>nan</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Q2943995</td>\n",
       "      <td>investments</td>\n",
       "      <td>nan</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Q65158292</td>\n",
       "      <td>investments</td>\n",
       "      <td>nan</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Q79189910</td>\n",
       "      <td>investments</td>\n",
       "      <td>nan</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Q98778444</td>\n",
       "      <td>investments</td>\n",
       "      <td>nan</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Q98931288</td>\n",
       "      <td>investments</td>\n",
       "      <td>nan</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Q130387411</td>\n",
       "      <td>investments</td>\n",
       "      <td>nan</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Q131651749</td>\n",
       "      <td>investments</td>\n",
       "      <td>nan</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Q753684</td>\n",
       "      <td>industries</td>\n",
       "      <td>Q112165934</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Q1052675</td>\n",
       "      <td>industries</td>\n",
       "      <td>Q112165979</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Q1375196</td>\n",
       "      <td>industries</td>\n",
       "      <td>Q1415395</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Q1375196</td>\n",
       "      <td>industries</td>\n",
       "      <td>Q112165940</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Q2943995</td>\n",
       "      <td>industries</td>\n",
       "      <td>Q112166054</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Q65158292</td>\n",
       "      <td>industries</td>\n",
       "      <td>Q112166054</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Q79189910</td>\n",
       "      <td>industries</td>\n",
       "      <td>Q112166041</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Q98778444</td>\n",
       "      <td>industries</td>\n",
       "      <td>Q607081</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>Q98778444</td>\n",
       "      <td>industries</td>\n",
       "      <td>Q112165215</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Q98931288</td>\n",
       "      <td>industries</td>\n",
       "      <td>Q112166090</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Q130387411</td>\n",
       "      <td>industries</td>\n",
       "      <td>Q112166038</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>Q131651749</td>\n",
       "      <td>industries</td>\n",
       "      <td>Q112165459</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>Q753684</td>\n",
       "      <td>products</td>\n",
       "      <td>Q5060160</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Q1052675</td>\n",
       "      <td>products</td>\n",
       "      <td>nan</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>Q1375196</td>\n",
       "      <td>products</td>\n",
       "      <td>nan</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Q2943995</td>\n",
       "      <td>products</td>\n",
       "      <td>nan</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Q65158292</td>\n",
       "      <td>products</td>\n",
       "      <td>nan</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Q79189910</td>\n",
       "      <td>products</td>\n",
       "      <td>nan</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Q98778444</td>\n",
       "      <td>products</td>\n",
       "      <td>Q11460</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Q98931288</td>\n",
       "      <td>products</td>\n",
       "      <td>nan</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Q130387411</td>\n",
       "      <td>products</td>\n",
       "      <td>Q138580</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>Q130387411</td>\n",
       "      <td>products</td>\n",
       "      <td>Q25380418</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>Q131651749</td>\n",
       "      <td>products</td>\n",
       "      <td>nan</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>Q753684</td>\n",
       "      <td>operating_area</td>\n",
       "      <td>nan</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Q1052675</td>\n",
       "      <td>operating_area</td>\n",
       "      <td>nan</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Q1375196</td>\n",
       "      <td>operating_area</td>\n",
       "      <td>nan</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Q2943995</td>\n",
       "      <td>operating_area</td>\n",
       "      <td>nan</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Q65158292</td>\n",
       "      <td>operating_area</td>\n",
       "      <td>nan</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Q79189910</td>\n",
       "      <td>operating_area</td>\n",
       "      <td>nan</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Q98778444</td>\n",
       "      <td>operating_area</td>\n",
       "      <td>nan</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Q98931288</td>\n",
       "      <td>operating_area</td>\n",
       "      <td>nan</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Q130387411</td>\n",
       "      <td>operating_area</td>\n",
       "      <td>nan</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Q131651749</td>\n",
       "      <td>operating_area</td>\n",
       "      <td>nan</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Q753684</td>\n",
       "      <td>location</td>\n",
       "      <td>nan</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Q1052675</td>\n",
       "      <td>location</td>\n",
       "      <td>nan</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Q1375196</td>\n",
       "      <td>location</td>\n",
       "      <td>nan</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Q2943995</td>\n",
       "      <td>location</td>\n",
       "      <td>nan</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Q65158292</td>\n",
       "      <td>location</td>\n",
       "      <td>nan</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Q79189910</td>\n",
       "      <td>location</td>\n",
       "      <td>nan</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Q98778444</td>\n",
       "      <td>location</td>\n",
       "      <td>nan</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Q98931288</td>\n",
       "      <td>location</td>\n",
       "      <td>nan</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Q130387411</td>\n",
       "      <td>location</td>\n",
       "      <td>nan</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Q131651749</td>\n",
       "      <td>location</td>\n",
       "      <td>nan</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Q753684</td>\n",
       "      <td>instance_of</td>\n",
       "      <td>Q43229</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Q753684</td>\n",
       "      <td>instance_of</td>\n",
       "      <td>Q210167</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Q753684</td>\n",
       "      <td>instance_of</td>\n",
       "      <td>Q1137109</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Q1052675</td>\n",
       "      <td>instance_of</td>\n",
       "      <td>Q43229</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Q1375196</td>\n",
       "      <td>instance_of</td>\n",
       "      <td>Q1762059</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Q2943995</td>\n",
       "      <td>instance_of</td>\n",
       "      <td>Q43229</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Q65158292</td>\n",
       "      <td>instance_of</td>\n",
       "      <td>Q43229</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Q79189910</td>\n",
       "      <td>instance_of</td>\n",
       "      <td>Q43229</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Q98778444</td>\n",
       "      <td>instance_of</td>\n",
       "      <td>Q43229</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Q98778444</td>\n",
       "      <td>instance_of</td>\n",
       "      <td>Q726870</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Q98778444</td>\n",
       "      <td>instance_of</td>\n",
       "      <td>Q76213285</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Q98931288</td>\n",
       "      <td>instance_of</td>\n",
       "      <td>Q43229</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Q130387411</td>\n",
       "      <td>instance_of</td>\n",
       "      <td>Q43229</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Q131651749</td>\n",
       "      <td>instance_of</td>\n",
       "      <td>Q43229</td>\n",
       "      <td>2026-02-27 12:14:20.443279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   company_qid item_description                 value  \\\n",
       "0      Q753684             isin          FR0010478248   \n",
       "1      Q753684             isin          US4659401040   \n",
       "2     Q1052675             isin          FR0000053506   \n",
       "3     Q1375196             isin          FR0010490920   \n",
       "4     Q2943995             isin          FR0010425595   \n",
       "5    Q65158292             isin          FR0011648716   \n",
       "6    Q79189910             isin          FR0013341781   \n",
       "7    Q98778444             isin          FR0000060840   \n",
       "8    Q98931288             isin          FR0000054421   \n",
       "9   Q130387411             isin          FR0012819381   \n",
       "10  Q131651749             isin          FR001400SVN0   \n",
       "11     Q753684    founding_year  1983-06-01T00:00:00Z   \n",
       "12    Q1052675    founding_year  1969-01-01T00:00:00Z   \n",
       "13    Q1375196    founding_year  2000-09-01T00:00:00Z   \n",
       "14    Q2943995    founding_year  1999-01-01T00:00:00Z   \n",
       "15   Q65158292    founding_year  2011-01-01T00:00:00Z   \n",
       "16   Q79189910    founding_year  2005-01-01T00:00:00Z   \n",
       "17   Q98778444    founding_year  1927-01-01T00:00:00Z   \n",
       "18   Q98778444    founding_year  1958-01-01T00:00:00Z   \n",
       "19   Q98931288    founding_year  1975-01-01T00:00:00Z   \n",
       "20  Q130387411    founding_year  1972-01-01T00:00:00Z   \n",
       "21  Q131651749    founding_year  2011-04-12T00:00:00Z   \n",
       "22     Q753684     subsidiaries               Q527336   \n",
       "23     Q753684     subsidiaries             Q15018011   \n",
       "24    Q1052675     subsidiaries                   nan   \n",
       "25    Q1375196     subsidiaries             Q16635235   \n",
       "26    Q2943995     subsidiaries                   nan   \n",
       "27   Q65158292     subsidiaries                   nan   \n",
       "28   Q79189910     subsidiaries                   nan   \n",
       "29   Q98778444     subsidiaries                   nan   \n",
       "30   Q98931288     subsidiaries               Q573356   \n",
       "31  Q130387411     subsidiaries            Q126880572   \n",
       "32  Q131651749     subsidiaries                   nan   \n",
       "33     Q753684      investments               Q527336   \n",
       "34    Q1052675      investments                   nan   \n",
       "35    Q1375196      investments                   nan   \n",
       "36    Q2943995      investments                   nan   \n",
       "37   Q65158292      investments                   nan   \n",
       "38   Q79189910      investments                   nan   \n",
       "39   Q98778444      investments                   nan   \n",
       "40   Q98931288      investments                   nan   \n",
       "41  Q130387411      investments                   nan   \n",
       "42  Q131651749      investments                   nan   \n",
       "43     Q753684       industries            Q112165934   \n",
       "44    Q1052675       industries            Q112165979   \n",
       "45    Q1375196       industries              Q1415395   \n",
       "46    Q1375196       industries            Q112165940   \n",
       "47    Q2943995       industries            Q112166054   \n",
       "48   Q65158292       industries            Q112166054   \n",
       "49   Q79189910       industries            Q112166041   \n",
       "50   Q98778444       industries               Q607081   \n",
       "51   Q98778444       industries            Q112165215   \n",
       "52   Q98931288       industries            Q112166090   \n",
       "53  Q130387411       industries            Q112166038   \n",
       "54  Q131651749       industries            Q112165459   \n",
       "55     Q753684         products              Q5060160   \n",
       "56    Q1052675         products                   nan   \n",
       "57    Q1375196         products                   nan   \n",
       "58    Q2943995         products                   nan   \n",
       "59   Q65158292         products                   nan   \n",
       "60   Q79189910         products                   nan   \n",
       "61   Q98778444         products                Q11460   \n",
       "62   Q98931288         products                   nan   \n",
       "63  Q130387411         products               Q138580   \n",
       "64  Q130387411         products             Q25380418   \n",
       "65  Q131651749         products                   nan   \n",
       "66     Q753684   operating_area                   nan   \n",
       "67    Q1052675   operating_area                   nan   \n",
       "68    Q1375196   operating_area                   nan   \n",
       "69    Q2943995   operating_area                   nan   \n",
       "70   Q65158292   operating_area                   nan   \n",
       "71   Q79189910   operating_area                   nan   \n",
       "72   Q98778444   operating_area                   nan   \n",
       "73   Q98931288   operating_area                   nan   \n",
       "74  Q130387411   operating_area                   nan   \n",
       "75  Q131651749   operating_area                   nan   \n",
       "76     Q753684         location                   nan   \n",
       "77    Q1052675         location                   nan   \n",
       "78    Q1375196         location                   nan   \n",
       "79    Q2943995         location                   nan   \n",
       "80   Q65158292         location                   nan   \n",
       "81   Q79189910         location                   nan   \n",
       "82   Q98778444         location                   nan   \n",
       "83   Q98931288         location                   nan   \n",
       "84  Q130387411         location                   nan   \n",
       "85  Q131651749         location                   nan   \n",
       "86     Q753684      instance_of                Q43229   \n",
       "87     Q753684      instance_of               Q210167   \n",
       "88     Q753684      instance_of              Q1137109   \n",
       "89    Q1052675      instance_of                Q43229   \n",
       "90    Q1375196      instance_of              Q1762059   \n",
       "91    Q2943995      instance_of                Q43229   \n",
       "92   Q65158292      instance_of                Q43229   \n",
       "93   Q79189910      instance_of                Q43229   \n",
       "94   Q98778444      instance_of                Q43229   \n",
       "95   Q98778444      instance_of               Q726870   \n",
       "96   Q98778444      instance_of             Q76213285   \n",
       "97   Q98931288      instance_of                Q43229   \n",
       "98  Q130387411      instance_of                Q43229   \n",
       "99  Q131651749      instance_of                Q43229   \n",
       "\n",
       "                  ingested_at  \n",
       "0  2026-02-27 12:14:20.443279  \n",
       "1  2026-02-27 12:14:20.443279  \n",
       "2  2026-02-27 12:14:20.443279  \n",
       "3  2026-02-27 12:14:20.443279  \n",
       "4  2026-02-27 12:14:20.443279  \n",
       "5  2026-02-27 12:14:20.443279  \n",
       "6  2026-02-27 12:14:20.443279  \n",
       "7  2026-02-27 12:14:20.443279  \n",
       "8  2026-02-27 12:14:20.443279  \n",
       "9  2026-02-27 12:14:20.443279  \n",
       "10 2026-02-27 12:14:20.443279  \n",
       "11 2026-02-27 12:14:20.443279  \n",
       "12 2026-02-27 12:14:20.443279  \n",
       "13 2026-02-27 12:14:20.443279  \n",
       "14 2026-02-27 12:14:20.443279  \n",
       "15 2026-02-27 12:14:20.443279  \n",
       "16 2026-02-27 12:14:20.443279  \n",
       "17 2026-02-27 12:14:20.443279  \n",
       "18 2026-02-27 12:14:20.443279  \n",
       "19 2026-02-27 12:14:20.443279  \n",
       "20 2026-02-27 12:14:20.443279  \n",
       "21 2026-02-27 12:14:20.443279  \n",
       "22 2026-02-27 12:14:20.443279  \n",
       "23 2026-02-27 12:14:20.443279  \n",
       "24 2026-02-27 12:14:20.443279  \n",
       "25 2026-02-27 12:14:20.443279  \n",
       "26 2026-02-27 12:14:20.443279  \n",
       "27 2026-02-27 12:14:20.443279  \n",
       "28 2026-02-27 12:14:20.443279  \n",
       "29 2026-02-27 12:14:20.443279  \n",
       "30 2026-02-27 12:14:20.443279  \n",
       "31 2026-02-27 12:14:20.443279  \n",
       "32 2026-02-27 12:14:20.443279  \n",
       "33 2026-02-27 12:14:20.443279  \n",
       "34 2026-02-27 12:14:20.443279  \n",
       "35 2026-02-27 12:14:20.443279  \n",
       "36 2026-02-27 12:14:20.443279  \n",
       "37 2026-02-27 12:14:20.443279  \n",
       "38 2026-02-27 12:14:20.443279  \n",
       "39 2026-02-27 12:14:20.443279  \n",
       "40 2026-02-27 12:14:20.443279  \n",
       "41 2026-02-27 12:14:20.443279  \n",
       "42 2026-02-27 12:14:20.443279  \n",
       "43 2026-02-27 12:14:20.443279  \n",
       "44 2026-02-27 12:14:20.443279  \n",
       "45 2026-02-27 12:14:20.443279  \n",
       "46 2026-02-27 12:14:20.443279  \n",
       "47 2026-02-27 12:14:20.443279  \n",
       "48 2026-02-27 12:14:20.443279  \n",
       "49 2026-02-27 12:14:20.443279  \n",
       "50 2026-02-27 12:14:20.443279  \n",
       "51 2026-02-27 12:14:20.443279  \n",
       "52 2026-02-27 12:14:20.443279  \n",
       "53 2026-02-27 12:14:20.443279  \n",
       "54 2026-02-27 12:14:20.443279  \n",
       "55 2026-02-27 12:14:20.443279  \n",
       "56 2026-02-27 12:14:20.443279  \n",
       "57 2026-02-27 12:14:20.443279  \n",
       "58 2026-02-27 12:14:20.443279  \n",
       "59 2026-02-27 12:14:20.443279  \n",
       "60 2026-02-27 12:14:20.443279  \n",
       "61 2026-02-27 12:14:20.443279  \n",
       "62 2026-02-27 12:14:20.443279  \n",
       "63 2026-02-27 12:14:20.443279  \n",
       "64 2026-02-27 12:14:20.443279  \n",
       "65 2026-02-27 12:14:20.443279  \n",
       "66 2026-02-27 12:14:20.443279  \n",
       "67 2026-02-27 12:14:20.443279  \n",
       "68 2026-02-27 12:14:20.443279  \n",
       "69 2026-02-27 12:14:20.443279  \n",
       "70 2026-02-27 12:14:20.443279  \n",
       "71 2026-02-27 12:14:20.443279  \n",
       "72 2026-02-27 12:14:20.443279  \n",
       "73 2026-02-27 12:14:20.443279  \n",
       "74 2026-02-27 12:14:20.443279  \n",
       "75 2026-02-27 12:14:20.443279  \n",
       "76 2026-02-27 12:14:20.443279  \n",
       "77 2026-02-27 12:14:20.443279  \n",
       "78 2026-02-27 12:14:20.443279  \n",
       "79 2026-02-27 12:14:20.443279  \n",
       "80 2026-02-27 12:14:20.443279  \n",
       "81 2026-02-27 12:14:20.443279  \n",
       "82 2026-02-27 12:14:20.443279  \n",
       "83 2026-02-27 12:14:20.443279  \n",
       "84 2026-02-27 12:14:20.443279  \n",
       "85 2026-02-27 12:14:20.443279  \n",
       "86 2026-02-27 12:14:20.443279  \n",
       "87 2026-02-27 12:14:20.443279  \n",
       "88 2026-02-27 12:14:20.443279  \n",
       "89 2026-02-27 12:14:20.443279  \n",
       "90 2026-02-27 12:14:20.443279  \n",
       "91 2026-02-27 12:14:20.443279  \n",
       "92 2026-02-27 12:14:20.443279  \n",
       "93 2026-02-27 12:14:20.443279  \n",
       "94 2026-02-27 12:14:20.443279  \n",
       "95 2026-02-27 12:14:20.443279  \n",
       "96 2026-02-27 12:14:20.443279  \n",
       "97 2026-02-27 12:14:20.443279  \n",
       "98 2026-02-27 12:14:20.443279  \n",
       "99 2026-02-27 12:14:20.443279  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataHub().preview_data()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn-data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
